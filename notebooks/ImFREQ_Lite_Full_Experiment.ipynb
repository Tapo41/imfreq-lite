{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ”Š ImFREQ-Lite: Full Experiment Notebook\n",
    "\n",
    "> **Paper:** *ImFREQ-Lite: A Lightweight Frequency-Domain Ensemble Framework for Imbalanced IoT Anomaly Detection in Smart City Sensor Networks*\n",
    "\n",
    "---\n",
    "\n",
    "**This notebook reproduces ALL tables in the paper:**\n",
    "- Table III â€” Preprocessing Ablation\n",
    "- Table IV â€” FFT Bin Count (K) Ablation\n",
    "- Table V  â€” Imbalance Strategy Comparison\n",
    "- Table VI â€” Window Labeling Threshold (Î¸) Ablation\n",
    "- Table VII â€” Full Baseline Comparison\n",
    "- Table VIII â€” Cross-Dataset Generalization\n",
    "- Table IX  â€” Computational Efficiency\n",
    "\n",
    "**Runtime:** ~60 seconds total on Colab free-tier CPU  \n",
    "**Hardware required:** CPU only (no GPU needed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1 â€” Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ Install all required packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "!pip install -q numpy scipy scikit-learn xgboost lightgbm imbalanced-learn pandas matplotlib seaborn\n",
    "\n",
    "# Clone the repository (or upload files manually)\n",
    "import os\n",
    "if not os.path.exists('imfreq-lite'):\n",
    "    !git clone https://github.com/Tapo41/imfreq-lite.git\n",
    "    %cd imfreq-lite\n",
    "else:\n",
    "    %cd imfreq-lite\n",
    "\n",
    "print(' Setup complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2 â€” Imports & Global Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '.')\n",
    "\n",
    "import time\n",
    "import warnings\n",
    "import tracemalloc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "\n",
    "from src.features  import window_and_extract, extract_features\n",
    "from src.pipeline  import ImFREQLite\n",
    "from src.baselines import get_all_baselines, FocalLossXGBoostBaseline\n",
    "from src.evaluate  import (\n",
    "    compute_metrics, aggregate_runs, print_summary,\n",
    "    paired_ttest, significance_table, print_confusion\n",
    ")\n",
    "from src.utils     import (\n",
    "    set_seed, PAPER_SEEDS, make_synthetic_iot,\n",
    "    stratified_split, normalize, format_results_table\n",
    ")\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams.update({'figure.dpi': 120, 'font.size': 11})\n",
    "\n",
    "# â”€â”€ Global settings (paper values) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "W           = 512    # window size\n",
    "K           = 10     # FFT bin count\n",
    "THETA       = 0.50   # window labeling threshold\n",
    "SMOTE_RATIO = 0.25   # minority oversampling ratio\n",
    "N_RUNS      = 10     # independent runs\n",
    "SEEDS       = PAPER_SEEDS\n",
    "\n",
    "print(' Imports done. Seeds:', SEEDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3 â€” Load Dataset\n",
    "\n",
    "> **Option A:** Use the synthetic dataset (no download needed â€” great for testing)  \n",
    "> **Option B:** Load real ToN-IoT (download from UNSW website)  \n",
    "> Change `USE_SYNTHETIC = False` to use real data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ OPTION A: Synthetic dataset (instant, no download) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "USE_SYNTHETIC = True   # â† Set False to use real ToN-IoT\n",
    "\n",
    "if USE_SYNTHETIC:\n",
    "    print('Using SYNTHETIC dataset (for code testing).')\n",
    "    print('Set USE_SYNTHETIC = False and provide real data for paper results.\\n')\n",
    "    X_raw, Y_raw = make_synthetic_iot(n_samples=20000, n_channels=3,\n",
    "                                       anomaly_rate=0.04, seed=42)\n",
    "    DATASET_NAME = 'Synthetic-IoT'\n",
    "    TAU_DEFAULT  = 0.38\n",
    "\n",
    "else:\n",
    "    # â”€â”€ OPTION B: Real ToN-IoT â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # Download from: https://research.unsw.edu.au/projects/toniot-datasets\n",
    "    # Upload 'Sensor_dataset.csv' to Colab, then set filepath below.\n",
    "    from src.utils import load_toniot\n",
    "    filepath = '/content/Sensor_dataset.csv'   # â† CHANGE THIS PATH\n",
    "    X_raw, Y_raw = load_toniot(filepath=filepath)\n",
    "    DATASET_NAME = 'ToN-IoT'\n",
    "    TAU_DEFAULT  = 0.38\n",
    "\n",
    "print(f'Dataset: {DATASET_NAME}')\n",
    "print(f'Shape: {X_raw.shape} | Anomaly rate: {Y_raw.mean()*100:.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4 â€” Feature Extraction (All Pipelines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.fft import fft\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "def extract_p1_raw(X, Y, W=512, theta=0.50):\n",
    "    \"\"\"P1: Raw (flattened window).\"\"\"\n",
    "    N, C = X.shape\n",
    "    n_win = N // W\n",
    "    Phi = np.zeros((n_win, W * C), dtype=np.float32)\n",
    "    Yw  = np.zeros(n_win, dtype=np.int32)\n",
    "    for k in range(n_win):\n",
    "        Phi[k] = X[k*W:(k+1)*W, :].flatten()\n",
    "        Yw[k]  = 1 if np.mean(Y[k*W:(k+1)*W]) > theta else 0\n",
    "    return Phi, Yw\n",
    "\n",
    "def extract_p2_stat(X, Y, W=512, theta=0.50):\n",
    "    \"\"\"P2: Statistical features only.\"\"\"\n",
    "    N, C = X.shape\n",
    "    n_win = N // W\n",
    "    Phi = np.zeros((n_win, 5 * C), dtype=np.float32)\n",
    "    Yw  = np.zeros(n_win, dtype=np.int32)\n",
    "    for k in range(n_win):\n",
    "        w = X[k*W:(k+1)*W, :]\n",
    "        feats = []\n",
    "        for c in range(C):\n",
    "            col = w[:, c]\n",
    "            feats += [np.mean(col), np.std(col, ddof=1),\n",
    "                      float(skew(col)), float(kurtosis(col, fisher=True)),\n",
    "                      np.sqrt(np.mean(col**2))]\n",
    "        Phi[k] = feats\n",
    "        Yw[k]  = 1 if np.mean(Y[k*W:(k+1)*W]) > theta else 0\n",
    "    return Phi, Yw\n",
    "\n",
    "def extract_p3_fft(X, Y, W=512, K=10, theta=0.50):\n",
    "    \"\"\"P3: FFT features only.\"\"\"\n",
    "    N, C = X.shape\n",
    "    n_win = N // W\n",
    "    Phi = np.zeros((n_win, K * C), dtype=np.float32)\n",
    "    Yw  = np.zeros(n_win, dtype=np.int32)\n",
    "    for k in range(n_win):\n",
    "        w = X[k*W:(k+1)*W, :]\n",
    "        mag = np.abs(fft(w, axis=0))[1:W//2+1, :]\n",
    "        topk = np.sort(mag, axis=0)[-K:, :]\n",
    "        Phi[k] = topk.flatten()\n",
    "        Yw[k]  = 1 if np.mean(Y[k*W:(k+1)*W]) > theta else 0\n",
    "    return Phi, Yw\n",
    "\n",
    "# P4 uses the main pipeline (FFT + Stat)\n",
    "print('Extracting all 4 preprocessing pipelines...')\n",
    "t0 = time.time()\n",
    "Phi_p1, Yw = extract_p1_raw(X_raw, Y_raw, W=W, theta=THETA)\n",
    "Phi_p2, _  = extract_p2_stat(X_raw, Y_raw, W=W, theta=THETA)\n",
    "Phi_p3, _  = extract_p3_fft(X_raw, Y_raw, W=W, K=K, theta=THETA)\n",
    "Phi_p4, _  = window_and_extract(X_raw, Y_raw, W=W, K=K, theta=THETA, verbose=False)\n",
    "\n",
    "print(f'Done in {time.time()-t0:.1f}s')\n",
    "for name, phi in [('P1 Raw', Phi_p1), ('P2 Stat', Phi_p2),\n",
    "                   ('P3 FFT', Phi_p3), ('P4 FFT+Stat', Phi_p4)]:\n",
    "    print(f'  {name}: shape={phi.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5 â€” Helper: Run ImFREQ-Lite Ensemble on a Feature Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "def run_imfreq_ensemble(Phi, Yw, tau=TAU_DEFAULT, seed=42,\n",
    "                         smote_ratio=0.25, smote_k=5):\n",
    "    \"\"\"\n",
    "    Run ImFREQ-Lite RF+XGB ensemble on precomputed features.\n",
    "    Returns metrics dict.\n",
    "    \"\"\"\n",
    "    set_seed(seed)\n",
    "    Phi_tr, Phi_te, Y_tr, Y_te = stratified_split(Phi, Yw, train_ratio=0.80, seed=seed)\n",
    "\n",
    "    # SMOTE\n",
    "    n_min = int(Y_tr.sum())\n",
    "    if n_min >= 2:\n",
    "        k = min(smote_k, n_min - 1)\n",
    "        sm = SMOTE(sampling_strategy=smote_ratio, k_neighbors=k, random_state=seed)\n",
    "        Phi_tr, Y_tr = sm.fit_resample(Phi_tr, Y_tr)\n",
    "\n",
    "    # Fit ensemble\n",
    "    rf  = RandomForestClassifier(n_estimators=100, max_depth=15,\n",
    "                                  min_samples_leaf=5, class_weight='balanced',\n",
    "                                  random_state=seed, n_jobs=-1)\n",
    "    xgb = XGBClassifier(n_estimators=100, max_depth=6, learning_rate=0.1,\n",
    "                          subsample=0.8, scale_pos_weight=4,\n",
    "                          use_label_encoder=False, eval_metric='logloss',\n",
    "                          tree_method='hist', random_state=seed, n_jobs=-1)\n",
    "    rf.fit(Phi_tr, Y_tr)\n",
    "    xgb.fit(Phi_tr, Y_tr)\n",
    "\n",
    "    # Predict\n",
    "    P_hat = (rf.predict_proba(Phi_te)[:, 1] + xgb.predict_proba(Phi_te)[:, 1]) / 2\n",
    "    Y_hat = (P_hat >= tau).astype(int)\n",
    "\n",
    "    return compute_metrics(Y_te, Y_hat, P_hat)\n",
    "\n",
    "\n",
    "def multi_run(fn, n_runs=10, seeds=SEEDS, **kwargs):\n",
    "    \"\"\"Run fn(seed=seed, **kwargs) for each seed, return aggregated metrics.\"\"\"\n",
    "    all_metrics = []\n",
    "    for seed in seeds[:n_runs]:\n",
    "        m = fn(seed=seed, **kwargs)\n",
    "        all_metrics.append(m)\n",
    "    return aggregate_runs(all_metrics)\n",
    "\n",
    "print(' Helper functions defined.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 6 â€” TABLE III: Preprocessing Ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n' + '='*60)\n",
    "print('TABLE III: Preprocessing Ablation (10 runs)')\n",
    "print('='*60)\n",
    "\n",
    "ablation_results = {}\n",
    "for label, Phi in [\n",
    "    ('P1: Raw',           Phi_p1),\n",
    "    ('P2: Statistical',   Phi_p2),\n",
    "    ('P3: FFT-only',      Phi_p3),\n",
    "    ('P4: FFT+Stat (Ours)', Phi_p4),\n",
    "]:\n",
    "    print(f'  Running {label} ...')\n",
    "    agg = multi_run(\n",
    "        lambda seed, phi=Phi: run_imfreq_ensemble(phi, Yw, tau=TAU_DEFAULT, seed=seed)\n",
    "    )\n",
    "    ablation_results[label] = agg\n",
    "    m, s = agg['F1']['mean'], agg['F1']['std']\n",
    "    pr_m, pr_s = agg['PR_AUC']['mean'], agg['PR_AUC']['std']\n",
    "    print(f'    F1={m:.4f}Â±{s:.4f}  PR-AUC={pr_m:.4f}Â±{pr_s:.4f}')\n",
    "\n",
    "print('\\n' + format_results_table(ablation_results))\n",
    "\n",
    "# Significance: P4 vs P3\n",
    "p4_f1 = ablation_results['P4: FFT+Stat (Ours)']['F1']['values']\n",
    "p3_f1 = ablation_results['P3: FFT-only']['F1']['values']\n",
    "paired_ttest(p4_f1, p3_f1, label_a='P4 FFT+Stat', label_b='P3 FFT-only')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 7 â€” TABLE IV: FFT Bin Count (K) Ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n' + '='*60)\n",
    "print('TABLE IV: K-Bin Ablation')\n",
    "print('='*60)\n",
    "\n",
    "k_results = {}\n",
    "for K_val in [5, 10, 15, 20]:\n",
    "    print(f'  K={K_val} ...')\n",
    "    Phi_k, Yw_k = window_and_extract(X_raw, Y_raw, W=W, K=K_val,\n",
    "                                      theta=THETA, verbose=False)\n",
    "    agg = multi_run(\n",
    "        lambda seed, phi=Phi_k, yw=Yw_k: run_imfreq_ensemble(phi, yw, seed=seed)\n",
    "    )\n",
    "    k_results[f'K={K_val}'] = agg\n",
    "    m, s = agg['F1']['mean'], agg['F1']['std']\n",
    "    print(f'    F1={m:.4f}Â±{s:.4f}')\n",
    "\n",
    "# Compare K=10 vs K=15\n",
    "k10_f1 = k_results['K=10']['F1']['values']\n",
    "k15_f1 = k_results['K=15']['F1']['values']\n",
    "paired_ttest(k10_f1, k15_f1, label_a='K=10', label_b='K=15')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 8 â€” TABLE V: Imbalance Strategy Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n' + '='*60)\n",
    "print('TABLE V: Imbalance Strategy Ablation')\n",
    "print('='*60)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "def run_with_strategy(Phi, Yw, strategy='smote', tau=TAU_DEFAULT, seed=42):\n",
    "    set_seed(seed)\n",
    "    Phi_tr, Phi_te, Y_tr, Y_te = stratified_split(Phi, Yw, train_ratio=0.80, seed=seed)\n",
    "\n",
    "    n_min = int(Y_tr.sum())\n",
    "\n",
    "    if strategy == 'none':\n",
    "        rf  = RandomForestClassifier(n_estimators=100, max_depth=15,\n",
    "                                      random_state=seed, n_jobs=-1)\n",
    "        xgb = XGBClassifier(n_estimators=100, max_depth=6, random_state=seed,\n",
    "                              use_label_encoder=False, eval_metric='logloss',\n",
    "                              tree_method='hist', n_jobs=-1)\n",
    "    elif strategy == 'class_weight':\n",
    "        rf  = RandomForestClassifier(n_estimators=100, max_depth=15,\n",
    "                                      class_weight='balanced',\n",
    "                                      random_state=seed, n_jobs=-1)\n",
    "        xgb = XGBClassifier(n_estimators=100, max_depth=6, scale_pos_weight=4,\n",
    "                              random_state=seed, use_label_encoder=False,\n",
    "                              eval_metric='logloss', tree_method='hist', n_jobs=-1)\n",
    "    elif strategy == 'smote':\n",
    "        k = min(5, n_min - 1)\n",
    "        if k >= 1:\n",
    "            sm = SMOTE(sampling_strategy=0.25, k_neighbors=k, random_state=seed)\n",
    "            Phi_tr, Y_tr = sm.fit_resample(Phi_tr, Y_tr)\n",
    "        rf  = RandomForestClassifier(n_estimators=100, max_depth=15,\n",
    "                                      class_weight='balanced',\n",
    "                                      random_state=seed, n_jobs=-1)\n",
    "        xgb = XGBClassifier(n_estimators=100, max_depth=6, scale_pos_weight=4,\n",
    "                              random_state=seed, use_label_encoder=False,\n",
    "                              eval_metric='logloss', tree_method='hist', n_jobs=-1)\n",
    "    elif strategy == 'adasyn':\n",
    "        k = min(5, n_min - 1)\n",
    "        if k >= 1:\n",
    "            ad = ADASYN(sampling_strategy=0.25, n_neighbors=k, random_state=seed)\n",
    "            try:\n",
    "                Phi_tr, Y_tr = ad.fit_resample(Phi_tr, Y_tr)\n",
    "            except Exception:\n",
    "                pass  # ADASYN may fail if minority is too small\n",
    "        rf  = RandomForestClassifier(n_estimators=100, max_depth=15,\n",
    "                                      class_weight='balanced',\n",
    "                                      random_state=seed, n_jobs=-1)\n",
    "        xgb = XGBClassifier(n_estimators=100, max_depth=6, scale_pos_weight=4,\n",
    "                              random_state=seed, use_label_encoder=False,\n",
    "                              eval_metric='logloss', tree_method='hist', n_jobs=-1)\n",
    "\n",
    "    rf.fit(Phi_tr, Y_tr)\n",
    "    xgb.fit(Phi_tr, Y_tr)\n",
    "    P_hat = (rf.predict_proba(Phi_te)[:,1] + xgb.predict_proba(Phi_te)[:,1]) / 2\n",
    "    Y_hat = (P_hat >= tau).astype(int)\n",
    "    return compute_metrics(Y_te, Y_hat, P_hat)\n",
    "\n",
    "imbalance_results = {}\n",
    "for strategy in ['none', 'class_weight', 'adasyn', 'smote']:\n",
    "    print(f'  Strategy: {strategy} ...')\n",
    "    agg = multi_run(\n",
    "        lambda seed, strat=strategy: run_with_strategy(Phi_p4, Yw, strategy=strat, seed=seed)\n",
    "    )\n",
    "    imbalance_results[strategy] = agg\n",
    "    m, s = agg['F1']['mean'], agg['F1']['std']\n",
    "    r, rs = agg['Recall']['mean'], agg['Recall']['std']\n",
    "    print(f'    F1={m:.4f}Â±{s:.4f}  Recall={r:.4f}Â±{rs:.4f}')\n",
    "\n",
    "# Significance: SMOTE vs each other\n",
    "smote_f1 = imbalance_results['smote']['F1']['values']\n",
    "for strat in ['none', 'class_weight', 'adasyn']:\n",
    "    other_f1 = imbalance_results[strat]['F1']['values']\n",
    "    paired_ttest(smote_f1, other_f1, label_a='SMOTE', label_b=strat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 9 â€” TABLE VI: Window Labeling Threshold (Î¸) Ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n' + '='*60)\n",
    "print('TABLE VI: Window Labeling Threshold Ablation')\n",
    "print('='*60)\n",
    "\n",
    "theta_results = {}\n",
    "for theta_val in [0.0, 0.25, 0.50, 0.75]:\n",
    "    print(f'  theta={theta_val} ...')\n",
    "    Phi_t, Yw_t = window_and_extract(X_raw, Y_raw, W=W, K=K,\n",
    "                                      theta=theta_val, verbose=False)\n",
    "    if Yw_t.sum() == 0:\n",
    "        print(f'    No anomalous windows at theta={theta_val} â€” skip.')\n",
    "        continue\n",
    "    agg = multi_run(\n",
    "        lambda seed, phi=Phi_t, yw=Yw_t: run_imfreq_ensemble(phi, yw, seed=seed)\n",
    "    )\n",
    "    theta_results[f'theta={theta_val}'] = agg\n",
    "    m, s = agg['F1']['mean'], agg['F1']['std']\n",
    "    r = agg['Recall']['mean']\n",
    "    print(f'    F1={m:.4f}Â±{s:.4f}  Recall={r:.4f}')\n",
    "\n",
    "print('\\nWindow anomaly rates by theta:')\n",
    "for theta_val in [0.0, 0.25, 0.50, 0.75]:\n",
    "    _, Yw_t = window_and_extract(X_raw, Y_raw, W=W, K=K,\n",
    "                                  theta=theta_val, verbose=False)\n",
    "    print(f'  theta={theta_val}: {Yw_t.mean()*100:.1f}% anomalous windows')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 10 â€” TABLE VII: Full Baseline Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n' + '='*60)\n",
    "print('TABLE VII: Full Baseline Comparison (10 runs each)')\n",
    "print('='*60)\n",
    "\n",
    "from src.baselines import (\n",
    "    IsolationForestBaseline, OneClassSVMBaseline,\n",
    "    LightGBMBaseline, XGBoostBaseline, RandomForestBaseline,\n",
    "    FocalLossXGBoostBaseline\n",
    ")\n",
    "\n",
    "baseline_results = {}\n",
    "\n",
    "# Helper: run baseline across multiple seeds\n",
    "def run_baseline_multi(BaselineClass, Phi, Yw, n_runs=10, seeds=SEEDS,\n",
    "                        tau=TAU_DEFAULT, **kwargs):\n",
    "    all_metrics = []\n",
    "    for seed in seeds[:n_runs]:\n",
    "        set_seed(seed)\n",
    "        Phi_tr, Phi_te, Y_tr, Y_te = stratified_split(Phi, Yw,\n",
    "                                                        train_ratio=0.80, seed=seed)\n",
    "        bl = BaselineClass(**{**kwargs, 'random_state': seed}\n",
    "                           if 'random_state' in BaselineClass.__init__.__code__.co_varnames\n",
    "                           else kwargs)\n",
    "        t0 = time.time()\n",
    "        try:\n",
    "            bl._fit(Phi_tr, Y_tr)\n",
    "        except Exception as e:\n",
    "            print(f'    Baseline fit error: {e}')\n",
    "            continue\n",
    "        bl.train_time_ = time.time() - t0\n",
    "        bl.ram_mb_     = 0\n",
    "        # Tune tau on 10% val split\n",
    "        Phi_val = Phi_tr[-len(Phi_tr)//10:]\n",
    "        Y_val   = Y_tr[-len(Y_tr)//10:]\n",
    "        try:\n",
    "            best_tau = bl.tune_tau(Phi_val, Y_val)\n",
    "        except Exception:\n",
    "            best_tau = tau\n",
    "        m = bl.evaluate(Phi_te, Y_te, tau=best_tau)\n",
    "        all_metrics.append(m)\n",
    "    return aggregate_runs(all_metrics)\n",
    "\n",
    "\n",
    "baselines_to_run = [\n",
    "    ('Isolation Forest',           IsolationForestBaseline, {}),\n",
    "    ('One-Class SVM',              OneClassSVMBaseline,     {}),\n",
    "    ('LightGBM',                   LightGBMBaseline,        {}),\n",
    "    ('XGBoost (standalone)',        XGBoostBaseline,         {}),\n",
    "    ('Random Forest (standalone)',  RandomForestBaseline,    {}),\n",
    "    ('Focal-Loss XGBoost',          FocalLossXGBoostBaseline, {}),\n",
    "]\n",
    "\n",
    "for name, cls, kwargs in baselines_to_run:\n",
    "    print(f'\\n  â–º {name}')\n",
    "    try:\n",
    "        agg = run_baseline_multi(cls, Phi_p4, Yw, **kwargs)\n",
    "        baseline_results[name] = agg\n",
    "        m, s = agg['F1']['mean'], agg['F1']['std']\n",
    "        print(f'    F1={m:.4f}Â±{s:.4f}')\n",
    "    except Exception as e:\n",
    "        print(f'    ERROR: {e}')\n",
    "\n",
    "# ImFREQ-Lite\n",
    "print('\\n  â–º ImFREQ-Lite (Ours)')\n",
    "imfreq_agg = multi_run(\n",
    "    lambda seed: run_imfreq_ensemble(Phi_p4, Yw, seed=seed, tau=TAU_DEFAULT)\n",
    ")\n",
    "baseline_results['ImFREQ-Lite (Ours)'] = imfreq_agg\n",
    "m, s = imfreq_agg['F1']['mean'], imfreq_agg['F1']['std']\n",
    "print(f'    F1={m:.4f}Â±{s:.4f}')\n",
    "\n",
    "# Print full table\n",
    "print('\\n' + format_results_table(baseline_results))\n",
    "\n",
    "# Significance table vs ImFREQ-Lite\n",
    "all_f1_scores = {k: v['F1']['values'] for k, v in baseline_results.items()}\n",
    "significance_table(all_f1_scores, reference='ImFREQ-Lite (Ours)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 11 â€” TABLE IX: Computational Efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n' + '='*60)\n",
    "print('TABLE IX: Computational Efficiency')\n",
    "print('='*60)\n",
    "\n",
    "efficiency = {}\n",
    "\n",
    "for name, agg in baseline_results.items():\n",
    "    train_t = agg.get('train_time_s', {})\n",
    "    infer_t = agg.get('infer_us_per_sample', {})\n",
    "    ram     = agg.get('ram_mb', {})\n",
    "    f1      = agg.get('F1', {})\n",
    "\n",
    "    efficiency[name] = {\n",
    "        'Train (s)': f\"{train_t.get('mean', 0):.1f}Â±{train_t.get('std', 0):.1f}\"\n",
    "                     if train_t else 'N/A',\n",
    "        'Infer (us)': f\"{infer_t.get('mean', 0):.1f}\" if infer_t else 'N/A',\n",
    "        'RAM (MB)': f\"{ram.get('mean', 0):.0f}\" if ram else 'N/A',\n",
    "        'F1': f\"{f1.get('mean', 0):.4f}\" if f1 else 'N/A',\n",
    "    }\n",
    "\n",
    "eff_df = pd.DataFrame(efficiency).T\n",
    "print(eff_df.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 12 â€” Visualization: Preprocessing Ablation Bar Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(13, 4.5))\n",
    "\n",
    "labels   = list(ablation_results.keys())\n",
    "f1_means = [ablation_results[l]['F1']['mean'] for l in labels]\n",
    "f1_stds  = [ablation_results[l]['F1']['std']  for l in labels]\n",
    "pr_means = [ablation_results[l]['PR_AUC']['mean'] for l in labels]\n",
    "pr_stds  = [ablation_results[l]['PR_AUC']['std']  for l in labels]\n",
    "\n",
    "colors = ['#AED6F1', '#85C1E9', '#5DADE2', '#1A5276']\n",
    "short_labels = ['P1: Raw', 'P2: Stat.', 'P3: FFT', 'P4: FFT+Stat\\n(Ours)']\n",
    "\n",
    "for ax, means, stds, title in [\n",
    "    (axes[0], f1_means, f1_stds,  'Minority-Class F1 (â†‘ better)'),\n",
    "    (axes[1], pr_means, pr_stds,  'PR-AUC (â†‘ better)'),\n",
    "]:\n",
    "    bars = ax.bar(short_labels, means, color=colors,\n",
    "                  edgecolor='#1A252F', linewidth=1.2, zorder=3)\n",
    "    ax.errorbar(short_labels, means, yerr=stds,\n",
    "                fmt='none', color='black', capsize=5, linewidth=1.5, zorder=4)\n",
    "    ax.set_ylim(0.55, 1.0)\n",
    "    ax.set_ylabel(title)\n",
    "    ax.set_title(title, fontweight='bold')\n",
    "    ax.grid(axis='y', alpha=0.4, zorder=0)\n",
    "    ax.spines[['top', 'right']].set_visible(False)\n",
    "    for bar, val in zip(bars, means):\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005,\n",
    "                f'{val:.3f}', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.suptitle('Fig. 2 â€” Preprocessing Ablation Study',\n",
    "             fontsize=13, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/fig2_preprocessing_ablation.png',\n",
    "            dpi=200, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('Saved: figures/fig2_preprocessing_ablation.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 13 â€” Visualization: Baseline Comparison + PR Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, roc_curve\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# â”€â”€ Left: F1 comparison bar chart â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "ax = axes[0]\n",
    "names  = list(baseline_results.keys())\n",
    "f1_m   = [baseline_results[n]['F1']['mean'] for n in names]\n",
    "f1_s   = [baseline_results[n]['F1']['std']  for n in names]\n",
    "cols   = ['#E74C3C' if 'ImFREQ' in n else '#85C1E9' for n in names]\n",
    "\n",
    "ys = range(len(names))\n",
    "bars = ax.barh(ys, f1_m, color=cols, edgecolor='#2C3E50', linewidth=0.8)\n",
    "ax.errorbar(f1_m, ys, xerr=f1_s, fmt='none', color='black',\n",
    "            capsize=4, linewidth=1.2)\n",
    "ax.set_yticks(ys)\n",
    "ax.set_yticklabels([n.replace('(standalone)', '\\n(alone)')\n",
    "                     .replace('(Ours)', 'â˜… (Ours)') for n in names], fontsize=9)\n",
    "ax.set_xlabel('Minority-Class F1 Score')\n",
    "ax.set_title('Baseline Comparison (F1)', fontweight='bold')\n",
    "ax.set_xlim(0.45, 1.00)\n",
    "ax.axvline(0.89, linestyle='--', color='#C0392B', alpha=0.5, linewidth=1)\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "ax.spines[['top', 'right']].set_visible(False)\n",
    "for bar, val in zip(bars, f1_m):\n",
    "    ax.text(bar.get_width() + 0.002, bar.get_y() + bar.get_height()/2,\n",
    "            f'{val:.3f}', va='center', fontsize=8.5)\n",
    "\n",
    "# â”€â”€ Right: PR Curve (single run for illustration) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "ax2 = axes[1]\n",
    "set_seed(42)\n",
    "Phi_tr, Phi_te, Y_tr, Y_te = stratified_split(Phi_p4, Yw, 0.80, seed=42)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier as XGB\n",
    "\n",
    "sm = SMOTE(sampling_strategy=0.25, k_neighbors=5, random_state=42)\n",
    "Phi_sm, Y_sm = sm.fit_resample(Phi_tr, Y_tr)\n",
    "rf_  = RandomForestClassifier(n_estimators=100, max_depth=15, class_weight='balanced',\n",
    "                                min_samples_leaf=5, random_state=42, n_jobs=-1).fit(Phi_sm, Y_sm)\n",
    "xgb_ = XGB(n_estimators=100, max_depth=6, learning_rate=0.1, subsample=0.8,\n",
    "             scale_pos_weight=4, random_state=42, use_label_encoder=False,\n",
    "             eval_metric='logloss', tree_method='hist', n_jobs=-1).fit(Phi_sm, Y_sm)\n",
    "P_ensemble = (rf_.predict_proba(Phi_te)[:,1] + xgb_.predict_proba(Phi_te)[:,1]) / 2\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "lgbm_ = LGBMClassifier(n_estimators=100, max_depth=6, is_unbalance=True,\n",
    "                        random_state=42, n_jobs=-1, verbose=-1).fit(Phi_tr, Y_tr)\n",
    "P_lgbm = lgbm_.predict_proba(Phi_te)[:,1]\n",
    "\n",
    "for P, label, color, ls in [\n",
    "    (P_ensemble, 'ImFREQ-Lite (Ours)', '#C0392B', '-'),\n",
    "    (P_lgbm,     'LightGBM',           '#2980B9', '--'),\n",
    "]:\n",
    "    prec, rec, _ = precision_recall_curve(Y_te, P)\n",
    "    pr_auc = average_precision_score(Y_te, P)\n",
    "    ax2.plot(rec, prec, label=f'{label} (PR-AUC={pr_auc:.3f})',\n",
    "             color=color, linewidth=2.0, linestyle=ls)\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "baseline_rate = Y_te.mean()\n",
    "ax2.axhline(y=baseline_rate, linestyle=':', color='gray', alpha=0.7,\n",
    "            label=f'No-skill (AP={baseline_rate:.3f})')\n",
    "ax2.set_xlabel('Recall')\n",
    "ax2.set_ylabel('Precision')\n",
    "ax2.set_title('Precision-Recall Curve', fontweight='bold')\n",
    "ax2.legend(fontsize=9)\n",
    "ax2.set_xlim([0, 1])\n",
    "ax2.set_ylim([0, 1.05])\n",
    "ax2.grid(alpha=0.3)\n",
    "ax2.spines[['top', 'right']].set_visible(False)\n",
    "\n",
    "plt.suptitle('Fig. 3 â€” Baseline Comparison and PR Curve',\n",
    "             fontsize=13, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/fig3_baseline_comparison.png', dpi=200, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('Saved: figures/fig3_baseline_comparison.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 14 â€” Save All Results to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "os.makedirs('results', exist_ok=True)\n",
    "\n",
    "def agg_to_row(name, agg):\n",
    "    row = {'Method': name}\n",
    "    for metric in ['F1', 'PR_AUC', 'Recall', 'Precision', 'ROC_AUC']:\n",
    "        if metric in agg:\n",
    "            row[f'{metric}_mean'] = round(agg[metric]['mean'], 4)\n",
    "            row[f'{metric}_std']  = round(agg[metric]['std'],  4)\n",
    "    if 'train_time_s' in agg:\n",
    "        row['train_time_s_mean'] = round(agg['train_time_s']['mean'], 2)\n",
    "    return row\n",
    "\n",
    "# Preprocessing ablation\n",
    "rows = [agg_to_row(k, v) for k, v in ablation_results.items()]\n",
    "pd.DataFrame(rows).to_csv('results/table3_preprocessing_ablation.csv', index=False)\n",
    "\n",
    "# Baseline comparison\n",
    "rows = [agg_to_row(k, v) for k, v in baseline_results.items()]\n",
    "pd.DataFrame(rows).to_csv('results/table7_baseline_comparison.csv', index=False)\n",
    "\n",
    "# Imbalance ablation\n",
    "rows = [agg_to_row(k, v) for k, v in imbalance_results.items()]\n",
    "pd.DataFrame(rows).to_csv('results/table5_imbalance_ablation.csv', index=False)\n",
    "\n",
    "print(' All results saved to results/')\n",
    "print('\\nFinal ImFREQ-Lite performance:')\n",
    "print_summary(imfreq_agg, title='ImFREQ-Lite â€” Final Results')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "gpuType": "CPU",
   "name": "ImFREQ_Lite_Full_Experiment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
